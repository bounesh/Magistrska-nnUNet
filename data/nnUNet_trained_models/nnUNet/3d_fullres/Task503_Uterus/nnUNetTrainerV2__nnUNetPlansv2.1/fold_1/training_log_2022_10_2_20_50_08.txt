Starting... 
2022-10-02 20:50:08.186566: Using splits from existing split file: /home/bonese/Magistrska-nnUNet/data/nnUNet_preprocessed/Task503_Uterus/splits_final.pkl 
2022-10-02 20:50:08.191988: The split file contains 5 splits. 
2022-10-02 20:50:08.192969: Desired fold for training: 1 
2022-10-02 20:50:08.193800: This split has 99 training and 25 validation cases. 
2022-10-02 20:50:08.312674: TRAINING KEYS:
 odict_keys(['Athens-1', 'Athens-2', 'Bologna-10', 'Bologna-11', 'Bologna-12', 'Bologna-14', 'Bologna-17', 'Bologna-19', 'Bologna-2', 'Bologna-20', 'Bologna-21', 'Bologna-22', 'Bologna-23', 'Bologna-24', 'Bologna-25', 'Bologna-26', 'Bologna-3', 'Bologna-30', 'Bologna-31', 'Bologna-32', 'Bologna-35', 'Bologna-36', 'Bologna-39', 'Bologna-40', 'Bologna-41', 'Bologna-42', 'Bologna-47', 'Bologna-49', 'Bologna-5', 'Bologna-7', 'Bologna-8', 'Forli-1', 'Forli-10', 'Forli-12', 'Forli-14', 'Forli-15', 'Forli-16', 'Forli-17', 'Forli-18', 'Forli-20', 'Forli-21', 'Forli-23', 'Forli-25', 'Forli-26', 'Forli-27', 'Forli-28', 'Forli-3', 'Forli-30', 'Forli-33', 'Forli-34', 'Forli-35', 'Forli-36', 'Forli-38', 'Forli-41', 'Forli-42', 'Forli-46', 'Forli-47', 'Forli-48', 'Forli-49', 'Forli-52', 'Forli-53', 'Forli-54', 'Forli-55', 'Forli-56', 'Forli-57', 'Forli-59', 'Forli-7', 'Forli-8', 'Forli-9', 'Madrid-13', 'Madrid-14', 'Madrid-15', 'Madrid-16', 'Madrid-19', 'Madrid-21', 'Madrid-23', 'Madrid-25', 'Madrid-26', 'Madrid-27', 'Madrid-28', 'Madrid-29', 'Madrid-3', 'Madrid-30', 'Madrid-32', 'Madrid-33', 'Madrid-35', 'Madrid-36', 'Madrid-37', 'Madrid-39', 'Madrid-4', 'Madrid-41', 'Madrid-42', 'Madrid-44', 'Madrid-45', 'Madrid-47', 'Madrid-5', 'Madrid-6', 'Madrid-8', 'Madrid-9']) 
2022-10-02 20:50:08.313801: VALIDATION KEYS:
 odict_keys(['Athens-4', 'Bologna-13', 'Bologna-15', 'Bologna-16', 'Bologna-29', 'Bologna-4', 'Bologna-44', 'Bologna-46', 'Bologna-6', 'Forli-11', 'Forli-2', 'Forli-22', 'Forli-32', 'Forli-4', 'Forli-40', 'Forli-44', 'Forli-45', 'Forli-51', 'Forli-58', 'Madrid-11', 'Madrid-12', 'Madrid-20', 'Madrid-22', 'Madrid-31', 'Madrid-40']) 
2022-10-02 20:50:15.701359: loading checkpoint /home/bonese/Magistrska-nnUNet/data/nnUNet_trained_models/nnUNet/3d_fullres/Task503_Uterus/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_latest.model train= True 
2022-10-02 20:50:19.698653: lr: 0.004384 
2022-10-02 20:50:52.457525: Unable to plot network architecture: 
2022-10-02 20:50:52.634325: No module named 'hiddenlayer' 
2022-10-02 20:50:52.765556: 
printing the network instead:
 
2022-10-02 20:50:52.904108: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2022-10-02 20:50:53.118770: 
 
2022-10-02 20:50:53.284435: 
epoch:  600 
2022-10-02 20:54:45.853823: train loss : -0.9432 
2022-10-02 20:55:04.179014: validation loss: -0.8717 
2022-10-02 20:55:04.207727: Average global foreground Dice: [0.9054] 
2022-10-02 20:55:04.229119: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 20:55:06.095968: lr: 0.004374 
2022-10-02 20:55:06.305934: saving checkpoint... 
2022-10-02 20:55:16.540671: done, saving took 10.44 seconds 
2022-10-02 20:55:16.552839: This epoch took 263.143088 s
 
2022-10-02 20:55:16.553922: 
epoch:  601 
2022-10-02 20:58:39.904367: train loss : -0.9478 
2022-10-02 20:58:58.477944: validation loss: -0.8560 
2022-10-02 20:58:58.500257: Average global foreground Dice: [0.8961] 
2022-10-02 20:58:58.501716: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 20:59:00.709255: lr: 0.004364 
2022-10-02 20:59:00.710744: This epoch took 224.155793 s
 
2022-10-02 20:59:00.712199: 
epoch:  602 
2022-10-02 21:02:33.310876: train loss : -0.9479 
2022-10-02 21:02:52.045480: validation loss: -0.8598 
2022-10-02 21:02:52.065909: Average global foreground Dice: [0.8932] 
2022-10-02 21:02:52.067097: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:02:53.983871: lr: 0.004354 
2022-10-02 21:02:53.985243: This epoch took 233.271807 s
 
2022-10-02 21:02:53.986472: 
epoch:  603 
2022-10-02 21:06:23.374445: train loss : -0.9417 
2022-10-02 21:06:41.907902: validation loss: -0.8560 
2022-10-02 21:06:41.916786: Average global foreground Dice: [0.8987] 
2022-10-02 21:06:41.917878: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:06:43.578282: lr: 0.004344 
2022-10-02 21:06:43.579590: This epoch took 229.592034 s
 
2022-10-02 21:06:43.580683: 
epoch:  604 
2022-10-02 21:10:26.934983: train loss : -0.9386 
2022-10-02 21:10:45.571797: validation loss: -0.8615 
2022-10-02 21:10:45.577365: Average global foreground Dice: [0.8958] 
2022-10-02 21:10:45.578610: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:10:47.287485: lr: 0.004334 
2022-10-02 21:10:47.288769: This epoch took 243.707021 s
 
2022-10-02 21:10:47.289810: 
epoch:  605 
2022-10-02 21:14:15.039061: train loss : -0.9468 
2022-10-02 21:14:32.435071: validation loss: -0.8473 
2022-10-02 21:14:32.462181: Average global foreground Dice: [0.8824] 
2022-10-02 21:14:32.463881: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:14:34.143594: lr: 0.004325 
2022-10-02 21:14:34.145106: This epoch took 226.854213 s
 
2022-10-02 21:14:34.146357: 
epoch:  606 
2022-10-02 21:18:07.425035: train loss : -0.9470 
2022-10-02 21:18:25.202965: validation loss: -0.8476 
2022-10-02 21:18:25.222691: Average global foreground Dice: [0.8886] 
2022-10-02 21:18:25.429929: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:18:26.949253: lr: 0.004315 
2022-10-02 21:18:26.950551: This epoch took 232.802866 s
 
2022-10-02 21:18:26.951661: 
epoch:  607 
2022-10-02 21:21:57.902524: train loss : -0.9508 
2022-10-02 21:22:14.893941: validation loss: -0.8672 
2022-10-02 21:22:14.903789: Average global foreground Dice: [0.9049] 
2022-10-02 21:22:14.905047: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:22:17.171276: lr: 0.004305 
2022-10-02 21:22:17.373160: This epoch took 230.420435 s
 
2022-10-02 21:22:17.374555: 
epoch:  608 
2022-10-02 21:25:49.235531: train loss : -0.9514 
2022-10-02 21:26:07.365816: validation loss: -0.8724 
2022-10-02 21:26:07.376671: Average global foreground Dice: [0.8978] 
2022-10-02 21:26:07.377907: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:26:09.478928: lr: 0.004295 
2022-10-02 21:26:09.480279: This epoch took 232.104485 s
 
2022-10-02 21:26:09.481307: 
epoch:  609 
2022-10-02 21:29:36.860753: train loss : -0.9519 
2022-10-02 21:29:55.178820: validation loss: -0.8571 
2022-10-02 21:29:55.212675: Average global foreground Dice: [0.8945] 
2022-10-02 21:29:55.414654: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:29:57.528922: lr: 0.004285 
2022-10-02 21:29:57.533971: This epoch took 228.051613 s
 
2022-10-02 21:29:57.535105: 
epoch:  610 
2022-10-02 21:33:21.774765: train loss : -0.9512 
2022-10-02 21:33:40.102816: validation loss: -0.8704 
2022-10-02 21:33:40.113744: Average global foreground Dice: [0.9007] 
2022-10-02 21:33:40.115015: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:33:42.158793: lr: 0.004275 
2022-10-02 21:33:42.160073: This epoch took 224.623925 s
 
2022-10-02 21:33:42.161326: 
epoch:  611 
2022-10-02 21:37:07.072070: train loss : -0.9547 
2022-10-02 21:37:25.809756: validation loss: -0.8691 
2022-10-02 21:37:25.836107: Average global foreground Dice: [0.8984] 
2022-10-02 21:37:25.837385: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:37:28.035019: lr: 0.004265 
2022-10-02 21:37:28.036425: This epoch took 225.873922 s
 
2022-10-02 21:37:28.037702: 
epoch:  612 
2022-10-02 21:40:47.576930: train loss : -0.9549 
2022-10-02 21:41:05.159750: validation loss: -0.8597 
2022-10-02 21:41:05.170689: Average global foreground Dice: [0.8959] 
2022-10-02 21:41:05.171940: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:41:07.482704: lr: 0.004255 
2022-10-02 21:41:07.483961: This epoch took 219.445044 s
 
2022-10-02 21:41:07.485115: 
epoch:  613 
