Starting... 
2022-10-02 20:50:08.186399: Using splits from existing split file: /home/bonese/Magistrska-nnUNet/data/nnUNet_preprocessed/Task503_Uterus/splits_final.pkl 
2022-10-02 20:50:08.192309: The split file contains 5 splits. 
2022-10-02 20:50:08.193253: Desired fold for training: 0 
2022-10-02 20:50:08.194012: This split has 99 training and 25 validation cases. 
2022-10-02 20:50:08.310269: TRAINING KEYS:
 odict_keys(['Athens-1', 'Athens-2', 'Athens-4', 'Bologna-10', 'Bologna-12', 'Bologna-13', 'Bologna-14', 'Bologna-15', 'Bologna-16', 'Bologna-17', 'Bologna-19', 'Bologna-2', 'Bologna-21', 'Bologna-22', 'Bologna-24', 'Bologna-25', 'Bologna-29', 'Bologna-3', 'Bologna-30', 'Bologna-31', 'Bologna-36', 'Bologna-39', 'Bologna-4', 'Bologna-40', 'Bologna-41', 'Bologna-42', 'Bologna-44', 'Bologna-46', 'Bologna-47', 'Bologna-49', 'Bologna-5', 'Bologna-6', 'Bologna-7', 'Forli-10', 'Forli-11', 'Forli-12', 'Forli-14', 'Forli-16', 'Forli-2', 'Forli-20', 'Forli-22', 'Forli-23', 'Forli-26', 'Forli-27', 'Forli-28', 'Forli-3', 'Forli-30', 'Forli-32', 'Forli-33', 'Forli-34', 'Forli-36', 'Forli-4', 'Forli-40', 'Forli-44', 'Forli-45', 'Forli-46', 'Forli-47', 'Forli-48', 'Forli-49', 'Forli-51', 'Forli-52', 'Forli-53', 'Forli-55', 'Forli-56', 'Forli-57', 'Forli-58', 'Forli-59', 'Forli-7', 'Forli-9', 'Madrid-11', 'Madrid-12', 'Madrid-14', 'Madrid-15', 'Madrid-20', 'Madrid-21', 'Madrid-22', 'Madrid-23', 'Madrid-25', 'Madrid-26', 'Madrid-27', 'Madrid-28', 'Madrid-29', 'Madrid-30', 'Madrid-31', 'Madrid-35', 'Madrid-36', 'Madrid-37', 'Madrid-39', 'Madrid-4', 'Madrid-40', 'Madrid-41', 'Madrid-42', 'Madrid-44', 'Madrid-45', 'Madrid-47', 'Madrid-5', 'Madrid-6', 'Madrid-8', 'Madrid-9']) 
2022-10-02 20:50:08.311492: VALIDATION KEYS:
 odict_keys(['Bologna-11', 'Bologna-20', 'Bologna-23', 'Bologna-26', 'Bologna-32', 'Bologna-35', 'Bologna-8', 'Forli-1', 'Forli-15', 'Forli-17', 'Forli-18', 'Forli-21', 'Forli-25', 'Forli-35', 'Forli-38', 'Forli-41', 'Forli-42', 'Forli-54', 'Forli-8', 'Madrid-13', 'Madrid-16', 'Madrid-19', 'Madrid-3', 'Madrid-32', 'Madrid-33']) 
2022-10-02 20:50:15.973520: loading checkpoint /home/bonese/Magistrska-nnUNet/data/nnUNet_trained_models/nnUNet/3d_fullres/Task503_Uterus/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_latest.model train= True 
2022-10-02 20:50:20.054707: lr: 0.000675 
2022-10-02 20:50:43.845643: Unable to plot network architecture: 
2022-10-02 20:50:44.380203: No module named 'hiddenlayer' 
2022-10-02 20:50:44.823343: 
printing the network instead:
 
2022-10-02 20:50:45.226385: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2022-10-02 20:50:45.605979: 
 
2022-10-02 20:50:45.987237: 
epoch:  950 
2022-10-02 20:54:23.934852: train loss : -0.9654 
2022-10-02 20:54:42.933771: validation loss: -0.8952 
2022-10-02 20:54:42.944431: Average global foreground Dice: [0.9149] 
2022-10-02 20:54:42.945780: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 20:54:45.287974: lr: 0.000662 
2022-10-02 20:54:45.292913: This epoch took 238.829852 s
 
2022-10-02 20:54:45.294070: 
epoch:  951 
2022-10-02 20:58:19.084881: train loss : -0.9632 
2022-10-02 20:58:36.968806: validation loss: -0.8996 
2022-10-02 20:58:36.970768: Average global foreground Dice: [0.9192] 
2022-10-02 20:58:36.972104: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 20:58:39.253940: lr: 0.00065 
2022-10-02 20:58:39.255417: This epoch took 233.960206 s
 
2022-10-02 20:58:39.256556: 
epoch:  952 
2022-10-02 21:02:01.065390: train loss : -0.9646 
2022-10-02 21:02:18.572716: validation loss: -0.8890 
2022-10-02 21:02:18.596829: Average global foreground Dice: [0.9113] 
2022-10-02 21:02:18.598216: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:02:20.217192: lr: 0.000638 
2022-10-02 21:02:20.218580: This epoch took 220.960776 s
 
2022-10-02 21:02:20.219862: 
epoch:  953 
2022-10-02 21:05:45.192380: train loss : -0.9635 
2022-10-02 21:06:03.925608: validation loss: -0.8996 
2022-10-02 21:06:03.946012: Average global foreground Dice: [0.9195] 
2022-10-02 21:06:03.956721: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:06:06.699434: lr: 0.000626 
2022-10-02 21:06:06.700654: This epoch took 226.479514 s
 
2022-10-02 21:06:06.701724: 
epoch:  954 
2022-10-02 21:09:50.717203: train loss : -0.9645 
2022-10-02 21:10:09.149795: validation loss: -0.9004 
2022-10-02 21:10:09.157893: Average global foreground Dice: [0.9211] 
2022-10-02 21:10:09.158977: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:10:10.966234: lr: 0.000614 
2022-10-02 21:10:10.969327: This epoch took 244.266450 s
 
2022-10-02 21:10:10.981306: 
epoch:  955 
2022-10-02 21:13:49.210865: train loss : -0.9638 
2022-10-02 21:14:07.032039: validation loss: -0.9015 
2022-10-02 21:14:07.047293: Average global foreground Dice: [0.9214] 
2022-10-02 21:14:07.048904: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:14:08.103215: lr: 0.000601 
2022-10-02 21:14:08.104661: This epoch took 237.122199 s
 
2022-10-02 21:14:08.105903: 
epoch:  956 
2022-10-02 21:17:36.485028: train loss : -0.9637 
2022-10-02 21:17:55.258815: validation loss: -0.9035 
2022-10-02 21:17:55.270293: Average global foreground Dice: [0.9256] 
2022-10-02 21:17:55.280265: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:17:57.436945: lr: 0.000589 
2022-10-02 21:17:57.438353: This epoch took 229.330971 s
 
2022-10-02 21:17:57.439528: 
epoch:  957 
2022-10-02 21:21:20.375060: train loss : -0.9638 
2022-10-02 21:21:39.350501: validation loss: -0.9007 
2022-10-02 21:21:39.368878: Average global foreground Dice: [0.9222] 
2022-10-02 21:21:39.370215: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:21:41.626914: lr: 0.000577 
2022-10-02 21:21:41.630237: This epoch took 224.189457 s
 
2022-10-02 21:21:41.631509: 
epoch:  958 
2022-10-02 21:24:59.053845: train loss : -0.9643 
2022-10-02 21:25:17.644501: validation loss: -0.8993 
2022-10-02 21:25:17.670990: Average global foreground Dice: [0.9196] 
2022-10-02 21:25:17.672390: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:25:19.694624: lr: 0.000564 
2022-10-02 21:25:19.696034: This epoch took 218.063256 s
 
2022-10-02 21:25:19.697192: 
epoch:  959 
2022-10-02 21:28:38.562254: train loss : -0.9645 
2022-10-02 21:28:56.847917: validation loss: -0.8950 
2022-10-02 21:28:56.849863: Average global foreground Dice: [0.9176] 
2022-10-02 21:28:56.851236: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:28:58.464506: lr: 0.000552 
2022-10-02 21:28:58.465802: This epoch took 218.767537 s
 
2022-10-02 21:28:58.467018: 
epoch:  960 
2022-10-02 21:32:21.910327: train loss : -0.9647 
2022-10-02 21:32:40.757771: validation loss: -0.8928 
2022-10-02 21:32:40.770227: Average global foreground Dice: [0.9204] 
2022-10-02 21:32:40.783677: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:32:42.813937: lr: 0.000539 
2022-10-02 21:32:42.820758: This epoch took 224.352580 s
 
2022-10-02 21:32:42.821969: 
epoch:  961 
2022-10-02 21:36:04.089028: train loss : -0.9662 
2022-10-02 21:36:23.007704: validation loss: -0.9027 
2022-10-02 21:36:23.030087: Average global foreground Dice: [0.9249] 
2022-10-02 21:36:23.031444: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:36:24.622561: lr: 0.000527 
2022-10-02 21:36:24.623811: This epoch took 221.800621 s
 
2022-10-02 21:36:24.624847: 
epoch:  962 
2022-10-02 21:40:00.749377: train loss : -0.9638 
2022-10-02 21:40:19.497351: validation loss: -0.9011 
2022-10-02 21:40:19.511011: Average global foreground Dice: [0.9212] 
2022-10-02 21:40:19.512218: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2022-10-02 21:40:21.390091: lr: 0.000514 
2022-10-02 21:40:21.391516: This epoch took 236.765333 s
 
2022-10-02 21:40:21.392690: 
epoch:  963 
